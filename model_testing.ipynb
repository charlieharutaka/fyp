{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0ebddc67d66e39b7e3d074ada8acf97e20f48e4fc5e38c6b9893e7bed32264973",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.tacotron import Tacotron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of parameters is: 34767937\nTacotron(\n  (embedding): Embedding(128, 256)\n  (encoder): Encoder(\n    (prenet): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Dropout(p=0.5, inplace=False)\n      (3): Linear(in_features=256, out_features=256, bias=True)\n      (4): ReLU()\n      (5): Dropout(p=0.5, inplace=False)\n    )\n    (cbhg): CBHG(\n      (bank): ConvolutionBank(\n        (convolutions): ModuleList(\n          (0): Sequential(\n            (0): ConstantPad1d(padding=(0, 0), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (1): Sequential(\n            (0): ConstantPad1d(padding=(1, 0), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(2,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (2): Sequential(\n            (0): ConstantPad1d(padding=(1, 1), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (3): Sequential(\n            (0): ConstantPad1d(padding=(2, 1), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(4,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (4): Sequential(\n            (0): ConstantPad1d(padding=(2, 2), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(5,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (5): Sequential(\n            (0): ConstantPad1d(padding=(3, 2), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(6,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (6): Sequential(\n            (0): ConstantPad1d(padding=(3, 3), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (7): Sequential(\n            (0): ConstantPad1d(padding=(4, 3), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(8,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (8): Sequential(\n            (0): ConstantPad1d(padding=(4, 4), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(9,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (9): Sequential(\n            (0): ConstantPad1d(padding=(5, 4), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(10,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (10): Sequential(\n            (0): ConstantPad1d(padding=(5, 5), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (11): Sequential(\n            (0): ConstantPad1d(padding=(6, 5), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(12,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (12): Sequential(\n            (0): ConstantPad1d(padding=(6, 6), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(13,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (13): Sequential(\n            (0): ConstantPad1d(padding=(7, 6), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(14,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (14): Sequential(\n            (0): ConstantPad1d(padding=(7, 7), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(15,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n          (15): Sequential(\n            (0): ConstantPad1d(padding=(8, 7), value=0.0)\n            (1): Conv1d(256, 256, kernel_size=(16,), stride=(1,))\n            (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (3): ReLU()\n          )\n        )\n      )\n      (pool): Sequential(\n        (0): ConstantPad1d(padding=(1, 0), value=-inf)\n        (1): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n      )\n      (projection): Sequential(\n        (0): ConstantPad1d(padding=(1, 1), value=0.0)\n        (1): Conv1d(4096, 256, kernel_size=(3,), stride=(1,))\n        (2): ReLU()\n        (3): ConstantPad1d(padding=(1, 1), value=0.0)\n        (4): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n      )\n      (highway): Sequential(\n        (0): HighwayLayer(\n          (fc): Linear(in_features=256, out_features=512, bias=True)\n        )\n        (1): HighwayLayer(\n          (fc): Linear(in_features=256, out_features=512, bias=True)\n        )\n        (2): HighwayLayer(\n          (fc): Linear(in_features=256, out_features=512, bias=True)\n        )\n        (3): HighwayLayer(\n          (fc): Linear(in_features=256, out_features=512, bias=True)\n        )\n      )\n      (gru): GRU(256, 256, batch_first=True, bidirectional=True)\n    )\n  )\n  (decoder): Decoder(\n    (memory_layer): Linear(in_features=256, out_features=128, bias=False)\n    (pre_net): Sequential(\n      (0): Linear(in_features=256, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Dropout(p=0.1, inplace=False)\n      (3): Linear(in_features=128, out_features=128, bias=True)\n      (4): ReLU()\n      (5): Dropout(p=0.1, inplace=False)\n    )\n    (attention_rnn): LSTMCell(384, 1024)\n    (attention_dropout): Dropout(p=0.1, inplace=False)\n    (attention_layer): AttentionLayer(\n      (query): Linear(in_features=1024, out_features=128, bias=False)\n      (value): Linear(in_features=128, out_features=1, bias=False)\n      (location): LocationLayer(\n        (location_conv): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n        (location_dense): Linear(in_features=32, out_features=128, bias=False)\n      )\n    )\n    (decoder_rnn): LSTMCell(1280, 1024)\n    (decoder_dropout): Dropout(p=0.1, inplace=False)\n    (linear_projection): Linear(in_features=1280, out_features=256, bias=True)\n    (gate): Linear(in_features=1280, out_features=1, bias=True)\n  )\n  (postnet): Postnet(\n    (convolutions): Sequential(\n      (0): Sequential(\n        (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Identity()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n      (1): Sequential(\n        (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Identity()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n      (2): Sequential(\n        (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Identity()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n      (3): Sequential(\n        (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Identity()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n      (4): Sequential(\n        (0): Conv1d(512, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Tanh()\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "model = Tacotron(128)\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bbb0193368a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrandom_mels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\MiniConda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Documents\\GitHub\\fyp\\models\\tacotron.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text_inputs, text_lengths, mels)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[0membedded_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mencoder_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m         \u001b[0moutputs_postnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0moutputs_postnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutputs_postnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\MiniConda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Documents\\GitHub\\fyp\\models\\tacotron.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, encoder_out, decoder_inputs, memory_lengths)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;31m# Seq-first order for RNNs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mgo_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_go_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mdecoder_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m         \u001b[1;31m# decoder_inputs shape is now (time_out, batch, hidden_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mdecoder_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgo_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "random_text = torch.randint(0, 128, (8, 16))\n",
    "lengths = torch.full((8,), 16)\n",
    "random_mels = torch.randn((8, 256, 32))\n",
    "\n",
    "result = model(random_text, lengths, random_text)"
   ]
  }
 ]
}